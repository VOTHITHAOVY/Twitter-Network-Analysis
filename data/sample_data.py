# data/sample_data.py
import networkx as nx
import numpy as np
import pandas as pd

def create_power_law_network(n_nodes=200, avg_degree=20, seed=42):
    """
    T·∫°o m·∫°ng v·ªõi ph√¢n ph·ªëi b·∫≠c power-law
    M√¥ ph·ªèng c·∫•u tr√∫c m·∫°ng x√£ h·ªôi th·ª±c t·∫ø
    """
    print(f"üéØ T·∫†O M·∫†NG POWER-LAW: {n_nodes} nodes, degree TB: {avg_degree}")
    np.random.seed(seed)
    
    G = nx.DiGraph()
    nodes = range(1, n_nodes + 1)
    G.add_nodes_from(nodes)
    
    # T·∫°o danh s√°ch degrees theo ph√¢n ph·ªëi power-law
    degrees = []
    for i in range(n_nodes):
        # Ph√¢n ph·ªëi zipf (power-law)
        degree = np.random.zipf(1.6)
        degree = min(degree, n_nodes//2)  # Gi·ªõi h·∫°n max degree
        degree = max(degree, 1)  # ƒê·∫£m b·∫£o √≠t nh·∫•t 1 connection
        degrees.append(degree)
    
    # ƒêi·ªÅu ch·ªânh ƒë·ªÉ ƒë·∫°t degree trung b√¨nh mong mu·ªën
    current_avg = np.mean(degrees)
    scaling_factor = avg_degree / current_avg
    degrees = [int(d * scaling_factor) for d in degrees]
    degrees = [max(d, 1) for d in degrees]  # ƒê·∫£m b·∫£o √≠t nh·∫•t 1 connection
    
    print(f"‚Ä¢ Degree trung b√¨nh th·ª±c t·∫ø: {np.mean(degrees):.2f}")
    
    # Th√™m edges d·ª±a tr√™n degrees
    edges_count = 0
    for i, source in enumerate(nodes):
        num_edges = degrees[i]
        
        # T·∫°o danh s√°ch targets c√≥ tr·ªçng s·ªë (preferential attachment)
        targets = []
        weights = []
        
        for target in nodes:
            if target != source:
                # ∆Øu ti√™n k·∫øt n·ªëi ƒë·∫øn nodes c√≥ degree cao (preferential attachment)
                weight = G.degree(target) + 1  # +1 ƒë·ªÉ tr√°nh chia 0
                targets.append(target)
                weights.append(weight)
        
        if targets and weights:
            # Ch·ªçn targets v·ªõi x√°c su·∫•t t·ª∑ l·ªá v·ªõi weight
            weights = np.array(weights) / sum(weights)
            selected_targets = np.random.choice(
                targets, 
                size=min(num_edges, len(targets)), 
                replace=False, 
                p=weights
            )
            
            for target in selected_targets:
                G.add_edge(source, target)
                edges_count += 1
    
    print(f"‚úÖ ƒê√£ t·∫°o: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")
    
    # Ki·ªÉm tra ph√¢n ph·ªëi power-law
    actual_degrees = [d for n, d in G.degree()]
    print(f"‚Ä¢ Degree th·ª±c t·∫ø: TB={np.mean(actual_degrees):.2f}, Max={max(actual_degrees)}, Min={min(actual_degrees)}")
    
    return G

def create_network_with_communities(n_nodes=200, n_communities=4, intra_prob=0.3, inter_prob=0.02):
    """
    T·∫°o m·∫°ng v·ªõi c·∫•u tr√∫c communities r√µ r√†ng
    """
    print(f"üèòÔ∏è T·∫†O M·∫†NG V·ªöI {n_communities} COMMUNITIES...")
    
    G = nx.DiGraph()
    nodes = range(1, n_nodes + 1)
    G.add_nodes_from(nodes)
    
    # Ph√¢n chia nodes v√†o communities
    community_size = n_nodes // n_communities
    community_assignments = {}
    
    for i, node in enumerate(nodes):
        comm_id = i // community_size
        if comm_id >= n_communities:
            comm_id = n_communities - 1
        community_assignments[node] = comm_id
    
    # Th√™m edges v·ªõi x√°c su·∫•t ph·ª• thu·ªôc v√†o community
    edges_count = 0
    
    for i in nodes:
        comm_i = community_assignments[i]
        
        # S·ªë edges cho node i (variation)
        num_edges = np.random.poisson(15) + 5  # 5-25 edges m·ªói node
        
        for _ in range(num_edges):
            if np.random.random() < intra_prob:  # Edge trong community
                same_comm_nodes = [n for n in nodes if community_assignments[n] == comm_i and n != i]
                if same_comm_nodes:
                    target = np.random.choice(same_comm_nodes)
                    G.add_edge(i, target)
                    edges_count += 1
            else:  # Edge gi·ªØa c√°c communities
                other_comm_nodes = [n for n in nodes if community_assignments[n] != comm_i]
                if other_comm_nodes and np.random.random() < inter_prob:
                    target = np.random.choice(other_comm_nodes)
                    G.add_edge(i, target)
                    edges_count += 1
    
    print(f"‚úÖ ƒê√£ t·∫°o: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")
    print(f"‚Ä¢ S·ªë communities: {len(set(community_assignments.values()))}")
    
    # T√≠nh modularity ƒë·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng communities
    try:
        from community import community_louvain
        partition = community_louvain.best_partition(G.to_undirected())
        modularity = community_louvain.modularity(partition, G.to_undirected())
        print(f"‚Ä¢ Modularity: {modularity:.3f}")
    except:
        print("‚Ä¢ Kh√¥ng th·ªÉ t√≠nh modularity")
    
    return G, community_assignments

def export_network_stats(G, filename='network_stats.csv'):
    """
    Xu·∫•t th·ªëng k√™ m·∫°ng ra file CSV
    """
    print(f"üíæ ƒêANG XU·∫§T TH·ªêNG K√ä: {filename}")
    
    stats_data = []
    
    # T√≠nh c√°c centrality measures
    degree_centrality = nx.degree_centrality(G)
    betweenness_centrality = nx.betweenness_centrality(G, k=100)
    closeness_centrality = nx.closeness_centrality(G)
    pagerank = nx.pagerank(G)
    
    for node in G.nodes():
        stats_data.append({
            'node_id': node,
            'degree': G.degree(node),
            'in_degree': G.in_degree(node),
            'out_degree': G.out_degree(node),
            'degree_centrality': degree_centrality[node],
            'betweenness_centrality': betweenness_centrality[node],
            'closeness_centrality': closeness_centrality[node],
            'pagerank': pagerank[node]
        })
    
    df = pd.DataFrame(stats_data)
    df.to_csv(filename, index=False, encoding='utf-8')
    
    print(f"‚úÖ ƒê√£ xu·∫•t th·ªëng k√™ {len(df)} nodes")
    
    # Th·ªëng k√™ t·ªïng quan
    print(f"\nüìä TH·ªêNG K√ä T·ªîNG QUAN:")
    print(f"   - S·ªë nodes: {G.number_of_nodes()}")
    print(f"   - S·ªë edges: {G.number_of_edges()}")
    print(f"   - ƒê·ªì th·ªã c√≥ h∆∞·ªõng: {G.is_directed()}")
    print(f"   - S·ªë th√†nh ph·∫ßn li√™n th√¥ng: {nx.number_weakly_connected_components(G)}")
    
    return df

if __name__ == "__main__":
    # Test c√°c h√†m
    print("üß™ TEST T·∫†O DATASET M·∫™U...")
    
    # T·∫°o m·∫°ng power-law
    G1 = create_power_law_network(100, 15)
    
    print("\n" + "="*50)
    
    # T·∫°o m·∫°ng v·ªõi communities
    G2, comm_assign = create_network_with_communities(150, 4)
    
    print("\n" + "="*50)
    
    # Xu·∫•t th·ªëng k√™
    export_network_stats(G2, 'sample_network_stats.csv')